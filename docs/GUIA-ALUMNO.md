# Gu√≠a del Alumno - Entorno Hadoop

¬°Bienvenido al laboratorio de Hadoop! Esta gu√≠a te ayudar√° a aprender Big Data de forma pr√°ctica.

## üéØ Objetivos de Aprendizaje

Al completar este laboratorio, ser√°s capaz de:

1. Entender la arquitectura de Hadoop y HDFS
2. Manipular archivos en un sistema de archivos distribuido
3. Ejecutar consultas SQL sobre grandes vol√∫menes de datos usando Hive
4. Analizar datos de negocio con HiveQL
5. Comprender conceptos de procesamiento distribuido

## üìö Contenido del Laboratorio

### M√≥dulo 1: Introducci√≥n a HDFS (2-3 horas)
- ¬øQu√© es HDFS y por qu√© se usa?
- Comandos b√°sicos de l√≠nea de comandos
- Explorando datos en el sistema distribuido
- **Recurso**: [01-hdfs-basics.md](../examples/01-hdfs-basics.md)

### M√≥dulo 2: HiveQL B√°sico (3-4 horas)
- SELECT, WHERE, ORDER BY
- Funciones de agregaci√≥n (COUNT, SUM, AVG, MIN, MAX)
- GROUP BY y HAVING
- **Recurso**: [02-hive-queries.sql](../examples/02-hive-queries.sql) (Nivel 1 y 2)

### M√≥dulo 3: JOINs y Consultas Complejas (3-4 horas)
- INNER JOIN, LEFT JOIN
- Combinando m√∫ltiples tablas
- Subconsultas
- **Recurso**: [02-hive-queries.sql](../examples/02-hive-queries.sql) (Nivel 3 y 4)

### M√≥dulo 4: An√°lisis de Datos Avanzado (4-5 horas)
- An√°lisis temporal
- Segmentaci√≥n de clientes
- M√©tricas de negocio
- **Recurso**: [02-hive-queries.sql](../examples/02-hive-queries.sql) (Nivel 5)

### M√≥dulo 5: Proyecto Final (Variable)
- An√°lisis completo de datos
- **Recurso**: [03-ejercicios-alumnos.md](../examples/03-ejercicios-alumnos.md)

## üöÄ Setup Inicial

### Pre-requisitos

Antes de comenzar, aseg√∫rate de tener insta Docker Desktop:
- [Descargar Docker Desktop](https://www.docker.com/products/docker-desktop)
- RAM: M√≠nimo 8 GB
- Espacio en disco: ~5 GB libres

### Pasos de Instalaci√≥n

**1. Obt√©n el repositorio**
```bash
# Si tienes Git instalado:
git clone https://github.com/tu-usuario/hadoop-example.git
cd hadoop-example

# O descarga el ZIP desde GitHub y extr√°elo
```

**2. Inicia el entorno**
```bash
docker-compose up -d
```

Esto tomar√° unos minutos la primera vez (descargando im√°genes).

**3. Verifica que todo est√© corriendo**
```bash
docker-compose ps
```

Deber√≠as ver 6-7 contenedores en estado "Up".

**4. Carga inicial de datos**

Abre una terminal y ejecuta:

```bash
# Paso 1: Inicializar HDFS
docker exec -it namenode bash /scripts/init-hdfs.sh

# Paso 2: Cargar datos
docker exec -it namenode bash /scripts/load-data.sh

# Paso 3: Crear tablas Hive
docker exec -it hive-server beeline -u jdbc:hive2://localhost:10000 -f /scripts/create-hive-tables.sql
```

**5. Verifica la instalaci√≥n**

Abre tu navegador:
- HDFS UI: http://localhost:9870
- YARN UI: http://localhost:8088

¬°Listo! Ahora est√°s ready para empezar.

## üíª Trabajando con el Entorno

### Conectarse a HDFS

```bash
docker exec -it namenode bash
```

Una vez dentro, puedes ejecutar comandos HDFS:

```bash
# Ver archivos
hdfs dfs -ls /data/input

# Ver contenido de un CSV
hdfs dfs -cat /data/input/Productos.csv | head -10
```

Para salir:
```bash
exit
```

### Conectarse a Hive

```bash
docker exec -it hive-server beeline -u jdbc:hive2://localhost:10000
```

Dentro de beeline:

```sql
-- Usar la base de datos
USE educacion_db;

-- Ver tablas
SHOW TABLES;

-- Ejecutar una consulta
SELECT * FROM Productos LIMIT 10;

-- Salir
!quit
```

## üìä Datos Disponibles

El laboratorio incluye datos de un sistema de ventas con las siguientes tablas:

- **Clientes** (3,409 registros): Informaci√≥n de clientes
- **Productos** (293 registros): Cat√°logo de productos
- **Venta** (46,647 registros): Transacciones de venta
- **Empleados**: Personal de la empresa
- **Sucursales**: Ubicaciones de tiendas
- **Proveedores**: Proveedores de productos
- **Compra**: Historial de compras a proveedores
- **Gasto**: Gastos operativos
- **CanalDeVenta**: Canales de venta (Online, Tienda, etc.)
- **TiposDeGasto**: Categor√≠as de gastos
- **Calendario**: Tabla dimensional de fechas

## üéì Metodolog√≠a de Aprendizaje Sugerida

### 1. Aprender por Hacer
- Lee el concepto
- Ejecuta los ejemplos
- Intenta modificarlos
- Resuelve los ejercicios

### 2. Progresi√≥n Gradual
No te saltes niveles. Cada m√≥dulo construye sobre el anterior.

### 3. Toma Notas
Mant√©n un archivo `.sql` con tus consultas favoritas y aprendizajes.

###4. Pregunta
Si tienes dudas, no dudes en preguntar al instructor o buscar en la documentaci√≥n oficial.

## üèÜ Mejores Pr√°cticas

### Al Escribir Consultas

```sql
-- ‚úÖ BUENO: Formateo claro y legible
SELECT 
    c.Nombre_y_Apellido,
    c.Provincia,
    SUM(v.Precio * v.Cantidad) as Total_Gastado
FROM Venta v
INNER JOIN Clientes c ON v.IdCliente = c.ID
GROUP BY c.Nombre_y_Apellido, c.Provincia
ORDER BY Total_Gastado DESC
LIMIT 10;

-- ‚ùå MALO: Todo en una l√≠nea, dif√≠cil de leer
SELECT c.Nombre_y_Apellido, c.Provincia, SUM(v.Precio * v.Cantidad) as Total_Gastado FROM Venta v INNER JOIN Clientes c ON v.IdCliente = c.ID GROUP BY c.Nombre_y_Apellido, c.Provincia ORDER BY Total_Gastado DESC LIMIT 10;
```

### Nomenclatura
- Usa nombres descriptivos para alias
- Prefieres min√∫sculas para nombres de columnas creadas
- Usa MAY√öSCULAS para palabras clave SQL

### Antes de Ejecutar
- Usa `LIMIT` cuando explores datos
- Comenta tus consultas complejas
- Guarda las consultas que funcionen

## üêõ Soluci√≥n de Problemas Comunes

### "No such table"
```sql
-- Soluci√≥n: Verifica que est√°s en la base correcta
USE educacion_db;
SHOW TABLES;
```

### "Connection refused"
```bash
# Soluci√≥n: Verifica que los contenedores est√©n corriendo
docker-compose ps
docker-compose up -d
```

### La consulta tarda mucho
- Limita los resultados con `LIMIT`
- Verifica que est√©s filtrando correctamente
- Recuerda que es un entorno de aprendizaje, no producci√≥n

### Necesito reiniciar todo
```bash
# Detener
docker-compose down

# Iniciar de nuevo
docker-compose up -d
```

## üìñ Recursos Adicionales

### Documentaci√≥n
- [Apache Hive Language Manual](https://cwiki.apache.org/confluence/display/Hive/LanguageManual)
- [HDFS Commands](https://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/FileSystemShell.html)

### Cheat Sheets
- [HiveQL Quick Reference](https://hortonworks.com/wp-content/uploads/2016/05/Hortonworks.CheatSheet.SQLtoHive.pdf)

### Comunidad
- Stack Overflow: Busca `[hive]` o `[hdfs]`
- Foros de Apache Hive

## ‚úÖ Checklist de Progreso

### Semana 1: Fundamentos
- [ ] Complet√© setup inicial
- [ ] Ejecut√© todos los comandos b√°sicos de HDFS
- [ ] Realic√© consultas SELECT b√°sicas
- [ ] Entiendo WHERE, ORDER BY, LIMIT

### Semana 2: Agregaciones y Combinaciones
- [ ] Domino COUNT, SUM, AVG, MIN, MAX
- [ ] Uso GROUP BY correctamente
- [ ] Entiendo INNER JOIN
- [ ] Puedo combinar 2-3 tablas

### Semana 3: An√°lisis Avanzado
- [ ] Uso subconsultas
- [ ] Trabajo con fechas
- [ ] Creo reportes de negocio
- [ ] Resuelvo problemas complejos

### Semana 4: Proyecto Final
- [ ] Defin√≠ un problema de an√°lisis
- [ ] Dise√±√© las consultas necesarias
- [ ] Ejecut√© y valid√© resultados
- [ ] Present√© hallazgos

## üéâ Siguiente Nivel

Una vez que domines este laboratorio, podr√°s:
- Trabajar con clusters Hadoop reales
- Aprender Spark y procesamiento en memoria
- Explorar herramientas como Impala, Presto
- Implementar data warehouses en la nube (AWS EMR, Azure HDInsight)

---

**¬°Mucho √©xito en tu aprendizaje!** üöÄ

Si tienes alguna pregunta, no dudes en consultar con tu instructor.
